{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "redo",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPFYUoOiWhE6wlXoXN2ixKu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/marcoplacenti/protein_generation/blob/main/final/redo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hrh7uny1abve"
      },
      "source": [
        "from google.colab import drive\n",
        "import torch, sys\n",
        "import pandas as pd\n",
        "import numpy as np  \n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "from torchtext import data\n",
        "import torch.distributions as dist\n",
        "import random\n",
        "torch.cuda.empty_cache()\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 291,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sxw17ufMgNPt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aeca8da1-12fe-4042-a7c3-154550fde823"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 292,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qS6Bs38vydfG",
        "outputId": "eb14c26d-8b04-4cba-9c43-8cf2d3ce0f5b"
      },
      "source": [
        "cd /content/drive/MyDrive/'Colab Notebooks'/project/"
      ],
      "execution_count": 293,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/Colab Notebooks/project\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0acy6-F7gq0D"
      },
      "source": [
        "def process_data(data, vocab, max_seq):\n",
        "    token_to_id, id_to_token = {}, {}\n",
        "    \n",
        "    token_to_id[\"<PAD>\"] = 0\n",
        "    id_to_token[0] = \"<PAD>\"\n",
        "\n",
        "    token_to_id[\"<EOS>\"] = 1\n",
        "    id_to_token[1] = \"<EOS>\"\n",
        "\n",
        "    token_to_id[\"<DUMMY>\"] = 2\n",
        "    id_to_token[2] = \"<DUMMY>\"\n",
        "\n",
        "    for i, token in enumerate(vocab):\n",
        "        cum_i = len(token_to_id.keys())\n",
        "        if token != \"<PAD>\" and token != \"<EOS>\" and token != \"<DUMMY>\":\n",
        "            token_to_id[token] = cum_i\n",
        "            id_to_token[cum_i] = token\n",
        "            cum_i += 1\n",
        "\n",
        "    seq = []\n",
        "    for record in data.values:\n",
        "        tags = record[:-1]\n",
        "        sequence = record[-1]\n",
        "        \n",
        "        encoded_record = [token_to_id[tag] for tag in tags]\n",
        "\n",
        "        for char in sequence:\n",
        "            encoded_record.append(token_to_id[char])\n",
        "        #encoded_record.append(token_to_id[\"<EOS>\"])\n",
        "        \n",
        "        if len(sequence) < max_seq:\n",
        "            for i in range(max_seq-len(sequence)):\n",
        "                encoded_record.append(token_to_id[\"<PAD>\"])\n",
        "\n",
        "        seq.append(encoded_record)\n",
        "\n",
        "    return np.array(seq), token_to_id, id_to_token"
      ],
      "execution_count": 433,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "quzuw8D9g0RM"
      },
      "source": [
        "def get_data(dataset):\n",
        "    data = pd.read_csv(dataset)\n",
        "\n",
        "    data = data.replace(np.nan, '<DUMMY>', regex=True)\n",
        "    #data.drop(\"Unnamed: 0\", axis=1, inplace=True)\n",
        "    #data.drop(\"Entry\", axis=1, inplace=True)\n",
        "    #print(data.columns)\n",
        "    max_length = int(data['Sequence'].str.len().max())\n",
        "    data = data[data[\"Sequence\"].map(len) <= max_length]\n",
        "    vocab = set()\n",
        "    for col in data.columns:\n",
        "        if col != \"Sequence\":\n",
        "            vocab.update(data[col])\n",
        "\n",
        "    seq_len = []\n",
        "    max_seq = 0\n",
        "    for seq in data[\"Sequence\"]:\n",
        "        seq = [s for s in seq]\n",
        "        seq_len.append(len(seq))\n",
        "        if len(seq) > max_seq:\n",
        "            max_seq = len(seq)\n",
        "        vocab.update(seq)\n",
        "\n",
        "    vocab.update([\"<PAD>\"])\n",
        "    vocab.update([\"<EOS>\"])\n",
        "\n",
        "    return data, vocab, max_seq"
      ],
      "execution_count": 295,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pWooCQBjgyw5"
      },
      "source": [
        "class ProGen(nn.Module):\n",
        "  \n",
        "  def __init__(self, hid_size, vocab_size, n_head, n_layers, pf_size, max_len, device):\n",
        "    super().__init__()\n",
        "\n",
        "    self.device = device\n",
        "    self.hid_size = hid_size\n",
        "    self.pf_size = pf_size\n",
        "    self.max_len = max_len\n",
        "    self.embedding = nn.Embedding(vocab_size, hid_size)\n",
        "    self.position_enc = nn.Embedding(self.max_len, self.hid_size)\n",
        "    self.position_enc.weight.data = self.position_encoding_init(self.max_len, self.hid_size)\n",
        "    self.scale = torch.sqrt(torch.FloatTensor([self.hid_size])).to(device)\n",
        "\n",
        "    self.layer_norm = nn.LayerNorm(self.hid_size)\n",
        "    self.decoder_layer = nn.TransformerDecoderLayer(d_model=hid_size, nhead = n_head, dim_feedforward=self.pf_size)\n",
        "    self.decoder = nn.TransformerDecoder(self.decoder_layer, num_layers=n_layers, norm=self.layer_norm)\n",
        "    self.fc = nn.Linear(hid_size, vocab_size)\n",
        "    self._init_weights()\n",
        "  \n",
        "  def forward(self, x):\n",
        "    sent_len, batch_size = x.shape[0], x.shape[1]\n",
        "    memory_mask = self.generate_complete_mask(sent_len)\n",
        "    tgt_mask = self.generate_triangular_mask(sent_len)\n",
        "    memory = torch.zeros(1, batch_size, self.hid_size, device=self.device)\n",
        "\n",
        "    temp = x\n",
        "    temp = self.embedding(temp)\n",
        "\n",
        "    pos = torch.arange(0,sent_len).unsqueeze(1).repeat(1,batch_size).to(self.device)\n",
        "    temp_pos_emb = self.position_enc(pos)\n",
        "\n",
        "    temp = temp * self.scale + temp_pos_emb\n",
        "    temp = self.decoder(temp, memory, tgt_mask=tgt_mask)\n",
        "    temp = self.fc(temp)\n",
        "    return temp\n",
        "\n",
        "  def _init_weights(self):\n",
        "    for p in self.parameters():\n",
        "      if p.dim() > 1:\n",
        "        nn.init.xavier_uniform_(p)\n",
        "\n",
        "  def append_decoder_layer(self):\n",
        "    appended_mod = nn.TransformerDecoderLayer(d_model=hid_size, nhead = n_head).to(self.device)\n",
        "    for p in appended_mod.parameters():\n",
        "      if p.dim() > 1:\n",
        "        nn.init.xavier_uniform_(p)\n",
        "    model.decoder.layers.append(appended_mod)\n",
        "    model.decoder.num_layers += 1\n",
        "\n",
        "  def generate_triangular_mask(self, size):\n",
        "        r\"\"\"Generate a square mask for the sequence. The masked positions are filled with float('-inf').\n",
        "            Unmasked positions are filled with float(0.0).\n",
        "        \"\"\"\n",
        "        mask = (torch.triu(torch.ones(size, size)) == 1).transpose(0, 1)\n",
        "        mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0)).to(device)\n",
        "        return\n",
        "        \n",
        "  def generate_complete_mask(self, size):\n",
        "        r\"\"\"Generate a square mask for the sequence. The masked positions are filled with float('-inf').\n",
        "            Unmasked positions are filled with float(0.0).\n",
        "        \"\"\"\n",
        "        mask = torch.empty(size, size).to(device)\n",
        "        mask.fill_(float('-inf'))\n",
        "        return mask\n",
        "\n",
        "  def generate_sequence(self, src):\n",
        "    #src = [sent_len]\n",
        "    src = src.unsqueeze(1)\n",
        "    #src = [sent_len, 1]\n",
        "    generate_step = 0\n",
        "    while generate_step < 120:\n",
        "      out = self.forward(src)\n",
        "      #out = [sent_len + 1, 1, vocab_size]\n",
        "      out = torch.argmax(out[-1, :], dim=1) # [1]\n",
        "      out = out.unsqueeze(0) #[1,1]\n",
        "      src = torch.cat((src, out), dim=0)\n",
        "      generate_step += 1\n",
        "    src = src.squeeze(1)\n",
        "    return src\n",
        "  \n",
        "  def position_encoding_init(self, n_position, d_pos_vec):\n",
        "    ''' Init the sinusoid position encoding table '''\n",
        "\n",
        "    # keep dim 0 for padding token position encoding zero vector\n",
        "    position_enc = np.array([\n",
        "        [pos / np.power(10000, 2*i/d_pos_vec) for i in range(d_pos_vec)]\n",
        "        if pos != 0 else np.zeros(d_pos_vec) for pos in range(n_position)])\n",
        "\n",
        "    position_enc[1:, 0::2] = np.sin(position_enc[1:, 0::2]) # dim 2i\n",
        "    position_enc[1:, 1::2] = np.cos(position_enc[1:, 1::2]) # dim 2i+1\n",
        "    temp = torch.from_numpy(position_enc).type(torch.FloatTensor)\n",
        "    temp = temp.to(self.device)\n",
        "    return temp"
      ],
      "execution_count": 477,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "27AlSYY3hptC"
      },
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
      ],
      "execution_count": 297,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z1SpvL3Kkize"
      },
      "source": [
        "file = \"dataset.csv\"\n",
        "\n",
        "data, vocab, max_seq = get_data(file)\n",
        "seq, token_to_id, id_to_token = process_data(data, vocab, max_seq)"
      ],
      "execution_count": 519,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A4eX1Mqc-RDF",
        "outputId": "b50c428b-f9b6-4bb0-e4b5-ab64ae79dfcb"
      },
      "source": [
        "vocab_size = len(vocab)\n",
        "hid_size = 32\n",
        "pf_size = 16\n",
        "max_len = 120\n",
        "n_head = 4\n",
        "n_layer= 8\n",
        "model = ProGen(hid_size, vocab_size, n_head, n_layer, pf_size, max_len, device).to(device)\n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')"
      ],
      "execution_count": 520,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The model has 161,122 trainable parameters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sbGladr3YVjI"
      },
      "source": [
        "bptt = 35\n",
        "def get_batch(source, i):\n",
        "    seq_len = min(bptt, len(source) - 1 - i)\n",
        "    data = source[i:i+seq_len]\n",
        "    target = source[i+1:i+1+seq_len].reshape(-1)\n",
        "    return data, target"
      ],
      "execution_count": 521,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bfqTIEKvYX-I"
      },
      "source": [
        "seq=torch.from_numpy(seq)"
      ],
      "execution_count": 522,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JIKbWpBHlTju",
        "outputId": "6a0c82ba-2b35-41f0-d0b4-8e6ebed6db8d"
      },
      "source": [
        "stats = { 'epoch':[], 'train_loss': [], 'train_perplexity': [], 'test_loss': [], 'test_perplexity': [] }\n",
        "batch_size, epochs, clip = 16, 200, 500\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, betas=(0.9, 0.98), eps=1e-9)\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "model.train()\n",
        "\n",
        "for i in range(epochs):\n",
        "  data, targets = get_batch(seq, i)\n",
        "  optimizer.zero_grad()\n",
        "  output = model(data)\n",
        "  loss = criterion(output.view(-1, len(vocab)), targets)\n",
        "  loss.backward()\n",
        "  torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5)\n",
        "  optimizer.step()\n",
        "  total_loss += loss.item()\n",
        "  stats['epoch'].append(i)\n",
        "  stats['train_loss'].append(loss.item())\n",
        "  print(i,loss.item())"
      ],
      "execution_count": 523,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 7.0572710037231445\n",
            "1 6.997131824493408\n",
            "2 6.401858329772949\n",
            "3 6.000661373138428\n",
            "4 5.576284885406494\n",
            "5 5.16103982925415\n",
            "6 4.760715961456299\n",
            "7 4.394260406494141\n",
            "8 4.05190372467041\n",
            "9 3.7619428634643555\n",
            "10 3.5160813331604004\n",
            "11 3.297281503677368\n",
            "12 3.1341471672058105\n",
            "13 2.9941561222076416\n",
            "14 2.8661155700683594\n",
            "15 2.74867844581604\n",
            "16 2.651010274887085\n",
            "17 2.541937828063965\n",
            "18 2.485649347305298\n",
            "19 2.434159517288208\n",
            "20 2.3556766510009766\n",
            "21 2.285799741744995\n",
            "22 2.2607715129852295\n",
            "23 2.2502381801605225\n",
            "24 2.2273409366607666\n",
            "25 2.191627264022827\n",
            "26 2.2231199741363525\n",
            "27 2.1379897594451904\n",
            "28 2.3067879676818848\n",
            "29 2.190131187438965\n",
            "30 2.1345667839050293\n",
            "31 2.002493381500244\n",
            "32 2.1029579639434814\n",
            "33 2.165729284286499\n",
            "34 2.067625045776367\n",
            "35 1.9641345739364624\n",
            "36 1.9423843622207642\n",
            "37 1.9155405759811401\n",
            "38 1.8696199655532837\n",
            "39 1.864464282989502\n",
            "40 1.850059986114502\n",
            "41 2.36289381980896\n",
            "42 1.8393336534500122\n",
            "43 1.8214490413665771\n",
            "44 1.8456491231918335\n",
            "45 1.8190181255340576\n",
            "46 1.8209377527236938\n",
            "47 1.8104455471038818\n",
            "48 1.7878501415252686\n",
            "49 1.7999261617660522\n",
            "50 1.793288230895996\n",
            "51 1.7914984226226807\n",
            "52 1.8029146194458008\n",
            "53 1.8161870241165161\n",
            "54 1.8054373264312744\n",
            "55 1.8082964420318604\n",
            "56 1.8029102087020874\n",
            "57 1.7862591743469238\n",
            "58 1.7917109727859497\n",
            "59 1.762231707572937\n",
            "60 1.7703410387039185\n",
            "61 1.7795981168746948\n",
            "62 1.7782409191131592\n",
            "63 1.7954479455947876\n",
            "64 1.7764642238616943\n",
            "65 1.8534393310546875\n",
            "66 1.827815294265747\n",
            "67 1.828898549079895\n",
            "68 1.7921574115753174\n",
            "69 1.8096927404403687\n",
            "70 1.7984282970428467\n",
            "71 1.7710139751434326\n",
            "72 1.7691566944122314\n",
            "73 1.7771496772766113\n",
            "74 1.7513765096664429\n",
            "75 1.7613176107406616\n",
            "76 1.752017617225647\n",
            "77 1.749075174331665\n",
            "78 1.746593952178955\n",
            "79 1.7234958410263062\n",
            "80 1.7157841920852661\n",
            "81 1.7204738855361938\n",
            "82 1.7355064153671265\n",
            "83 1.711814284324646\n",
            "84 1.688228964805603\n",
            "85 1.6989349126815796\n",
            "86 1.6871204376220703\n",
            "87 1.6835417747497559\n",
            "88 1.6695854663848877\n",
            "89 1.6720044612884521\n",
            "90 1.6981250047683716\n",
            "91 1.7136287689208984\n",
            "92 1.72419273853302\n",
            "93 1.709580659866333\n",
            "94 1.7192894220352173\n",
            "95 1.7210174798965454\n",
            "96 1.7181780338287354\n",
            "97 1.7238093614578247\n",
            "98 1.7247989177703857\n",
            "99 1.7109230756759644\n",
            "100 1.7240277528762817\n",
            "101 1.707879900932312\n",
            "102 1.7246299982070923\n",
            "103 1.7150764465332031\n",
            "104 1.7310289144515991\n",
            "105 1.7168524265289307\n",
            "106 1.705959677696228\n",
            "107 1.707172155380249\n",
            "108 1.6917338371276855\n",
            "109 1.7171586751937866\n",
            "110 1.7024686336517334\n",
            "111 1.7041192054748535\n",
            "112 1.7066792249679565\n",
            "113 1.6883454322814941\n",
            "114 1.6991446018218994\n",
            "115 1.6929396390914917\n",
            "116 1.6897884607315063\n",
            "117 1.6935147047042847\n",
            "118 1.6786785125732422\n",
            "119 1.7171062231063843\n",
            "120 1.7253562211990356\n",
            "121 1.700818419456482\n",
            "122 1.815286636352539\n",
            "123 1.7430061101913452\n",
            "124 1.7125502824783325\n",
            "125 1.6985934972763062\n",
            "126 1.6689152717590332\n",
            "127 1.6413273811340332\n",
            "128 1.66716730594635\n",
            "129 1.6434736251831055\n",
            "130 1.6166377067565918\n",
            "131 1.6386724710464478\n",
            "132 1.6639442443847656\n",
            "133 1.6683305501937866\n",
            "134 1.657519817352295\n",
            "135 1.6868619918823242\n",
            "136 1.7167332172393799\n",
            "137 1.6749166250228882\n",
            "138 1.7505555152893066\n",
            "139 1.7206456661224365\n",
            "140 1.7367504835128784\n",
            "141 1.760522723197937\n",
            "142 1.7607425451278687\n",
            "143 1.7423365116119385\n",
            "144 1.748581051826477\n",
            "145 1.7508771419525146\n",
            "146 1.7796603441238403\n",
            "147 1.7961069345474243\n",
            "148 1.8127270936965942\n",
            "149 1.7872540950775146\n",
            "150 1.7980595827102661\n",
            "151 1.7985246181488037\n",
            "152 1.82553231716156\n",
            "153 1.8262184858322144\n",
            "154 1.77024507522583\n",
            "155 1.8350121974945068\n",
            "156 1.8299928903579712\n",
            "157 1.8155251741409302\n",
            "158 1.8456764221191406\n",
            "159 1.8187110424041748\n",
            "160 1.823211669921875\n",
            "161 1.840996265411377\n",
            "162 1.8393224477767944\n",
            "163 1.8928484916687012\n",
            "164 1.870442509651184\n",
            "165 1.880021095275879\n",
            "166 1.8758231401443481\n",
            "167 1.8948276042938232\n",
            "168 1.8783187866210938\n",
            "169 1.8729957342147827\n",
            "170 1.8736941814422607\n",
            "171 1.885599136352539\n",
            "172 1.9174981117248535\n",
            "173 1.8676071166992188\n",
            "174 1.9176234006881714\n",
            "175 1.9196393489837646\n",
            "176 1.8647254705429077\n",
            "177 1.8586158752441406\n",
            "178 1.8778178691864014\n",
            "179 1.8477232456207275\n",
            "180 1.840266466140747\n",
            "181 1.8345141410827637\n",
            "182 1.8072688579559326\n",
            "183 1.8369476795196533\n",
            "184 1.8264877796173096\n",
            "185 1.865457534790039\n",
            "186 1.8950303792953491\n",
            "187 1.8828835487365723\n",
            "188 1.8797640800476074\n",
            "189 1.8848522901535034\n",
            "190 1.8933311700820923\n",
            "191 1.880074143409729\n",
            "192 1.8625726699829102\n",
            "193 1.8803986310958862\n",
            "194 1.9112390279769897\n",
            "195 1.88826322555542\n",
            "196 1.940537929534912\n",
            "197 1.905497431755066\n",
            "198 1.897261619567871\n",
            "199 1.901060700416565\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "mcBrhx5dQr4b",
        "outputId": "41c66cf9-343f-4ba4-ea88-b71cba7b7ace"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(stats['epoch'], stats['train_loss'])\n",
        "plt.show()"
      ],
      "execution_count": 524,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P-clZE_xVnPG",
        "outputId": "b5128014-f57a-4f59-fd06-b632866044b9"
      },
      "source": [
        "test_x[1,50:]"
      ],
      "execution_count": 525,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([  2,   2,   2,   2,   2,   2,   2,   2,   2,   2, 492, 426, 426, 832,\n",
              "        607, 671, 144, 174, 933, 426, 607, 426,  84, 607, 426, 607,  45, 426,\n",
              "        607, 426,  45, 607, 164, 933, 607,  84,  40,  84, 806, 144, 144, 671,\n",
              "        144, 551, 956, 144, 164, 551,  40,  84, 144, 144, 551, 551, 607,  84,\n",
              "        671, 806, 806, 933,  84, 607, 100,  28, 806, 832, 956, 607, 832, 933,\n",
              "        100, 475, 100, 806, 164, 671, 100, 901,  84, 475, 551,  40, 426, 426,\n",
              "         84, 551, 607, 607, 572, 164, 164,  40, 956, 956, 100,  40, 475, 100,\n",
              "        901, 100, 806,  40,  40, 901, 806, 492, 174,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 525
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2cuMi3UAdKkI"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}