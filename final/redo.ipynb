{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "redo",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNhbWco7hBLeN04BOKqXrvN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/marcoplacenti/protein_generation/blob/main/final/redo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hrh7uny1abve"
      },
      "source": [
        "from google.colab import drive\n",
        "import torch, sys\n",
        "import pandas as pd\n",
        "import numpy as np  \n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "from torchtext import data\n",
        "import torch.distributions as dist\n",
        "import random\n",
        "torch.cuda.empty_cache()\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 291,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sxw17ufMgNPt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aeca8da1-12fe-4042-a7c3-154550fde823"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 292,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qS6Bs38vydfG",
        "outputId": "eb14c26d-8b04-4cba-9c43-8cf2d3ce0f5b"
      },
      "source": [
        "cd /content/drive/MyDrive/'Colab Notebooks'/project/"
      ],
      "execution_count": 293,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/Colab Notebooks/project\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0acy6-F7gq0D"
      },
      "source": [
        "def process_data(data, vocab, max_seq):\n",
        "    token_to_id, id_to_token = {}, {}\n",
        "    \n",
        "    token_to_id[\"<PAD>\"] = 0\n",
        "    id_to_token[0] = \"<PAD>\"\n",
        "\n",
        "    token_to_id[\"<EOS>\"] = 1\n",
        "    id_to_token[1] = \"<EOS>\"\n",
        "\n",
        "    token_to_id[\"<DUMMY>\"] = 2\n",
        "    id_to_token[2] = \"<DUMMY>\"\n",
        "\n",
        "    for i, token in enumerate(vocab):\n",
        "        cum_i = len(token_to_id.keys())\n",
        "        if token != \"<PAD>\" and token != \"<EOS>\" and token != \"<DUMMY>\":\n",
        "            token_to_id[token] = cum_i\n",
        "            id_to_token[cum_i] = token\n",
        "            cum_i += 1\n",
        "\n",
        "    seq = []\n",
        "    for record in data.values:\n",
        "        tags = record[:-1]\n",
        "        sequence = record[-1]\n",
        "        \n",
        "        encoded_record = [token_to_id[tag] for tag in tags]\n",
        "\n",
        "        for char in sequence:\n",
        "            encoded_record.append(token_to_id[char])\n",
        "        #encoded_record.append(token_to_id[\"<EOS>\"])\n",
        "        \n",
        "        if len(sequence) < max_seq:\n",
        "            for i in range(max_seq-len(sequence)):\n",
        "                encoded_record.append(token_to_id[\"<PAD>\"])\n",
        "\n",
        "        seq.append(encoded_record)\n",
        "\n",
        "    return np.array(seq), token_to_id, id_to_token"
      ],
      "execution_count": 433,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "quzuw8D9g0RM"
      },
      "source": [
        "def get_data(dataset):\n",
        "    data = pd.read_csv(dataset)\n",
        "\n",
        "    data = data.replace(np.nan, '<DUMMY>', regex=True)\n",
        "    #data.drop(\"Unnamed: 0\", axis=1, inplace=True)\n",
        "    #data.drop(\"Entry\", axis=1, inplace=True)\n",
        "    #print(data.columns)\n",
        "    max_length = int(data['Sequence'].str.len().max())\n",
        "    data = data[data[\"Sequence\"].map(len) <= max_length]\n",
        "    vocab = set()\n",
        "    for col in data.columns:\n",
        "        if col != \"Sequence\":\n",
        "            vocab.update(data[col])\n",
        "\n",
        "    seq_len = []\n",
        "    max_seq = 0\n",
        "    for seq in data[\"Sequence\"]:\n",
        "        seq = [s for s in seq]\n",
        "        seq_len.append(len(seq))\n",
        "        if len(seq) > max_seq:\n",
        "            max_seq = len(seq)\n",
        "        vocab.update(seq)\n",
        "\n",
        "    vocab.update([\"<PAD>\"])\n",
        "    vocab.update([\"<EOS>\"])\n",
        "\n",
        "    return data, vocab, max_seq"
      ],
      "execution_count": 295,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pWooCQBjgyw5"
      },
      "source": [
        "class ProGen(nn.Module):\n",
        "  \n",
        "  def __init__(self, hid_size, vocab_size, n_head, n_layers, pf_size, max_len, device):\n",
        "    super().__init__()\n",
        "\n",
        "    self.device = device\n",
        "    self.hid_size = hid_size\n",
        "    self.pf_size = pf_size\n",
        "    self.max_len = max_len\n",
        "    self.embedding = nn.Embedding(vocab_size, hid_size)\n",
        "    self.position_enc = nn.Embedding(self.max_len, self.hid_size)\n",
        "    self.position_enc.weight.data = self.position_encoding_init(self.max_len, self.hid_size)\n",
        "    self.scale = torch.sqrt(torch.FloatTensor([self.hid_size])).to(device)\n",
        "\n",
        "    self.layer_norm = nn.LayerNorm(self.hid_size)\n",
        "    self.decoder_layer = nn.TransformerDecoderLayer(d_model=hid_size, nhead = n_head, dim_feedforward=self.pf_size)\n",
        "    self.decoder = nn.TransformerDecoder(self.decoder_layer, num_layers=n_layers, norm=self.layer_norm)\n",
        "    self.fc = nn.Linear(hid_size, vocab_size)\n",
        "    self._init_weights()\n",
        "  \n",
        "  def forward(self, x):\n",
        "    sent_len, batch_size = x.shape[0], x.shape[1]\n",
        "    memory_mask = self.generate_complete_mask(sent_len)\n",
        "    tgt_mask = self.generate_triangular_mask(sent_len)\n",
        "    memory = torch.zeros(1, batch_size, self.hid_size, device=self.device)\n",
        "\n",
        "    temp = x\n",
        "    temp = self.embedding(temp)\n",
        "\n",
        "    pos = torch.arange(0,sent_len).unsqueeze(1).repeat(1,batch_size).to(self.device)\n",
        "    temp_pos_emb = self.position_enc(pos)\n",
        "\n",
        "    temp = temp * self.scale + temp_pos_emb\n",
        "    temp = self.decoder(temp, memory, tgt_mask=tgt_mask)\n",
        "    temp = self.fc(temp)\n",
        "    return temp\n",
        "\n",
        "  def _init_weights(self):\n",
        "    for p in self.parameters():\n",
        "      if p.dim() > 1:\n",
        "        nn.init.xavier_uniform_(p)\n",
        "\n",
        "  def append_decoder_layer(self):\n",
        "    appended_mod = nn.TransformerDecoderLayer(d_model=hid_size, nhead = n_head).to(self.device)\n",
        "    for p in appended_mod.parameters():\n",
        "      if p.dim() > 1:\n",
        "        nn.init.xavier_uniform_(p)\n",
        "    model.decoder.layers.append(appended_mod)\n",
        "    model.decoder.num_layers += 1\n",
        "\n",
        "  def generate_triangular_mask(self, size):\n",
        "        r\"\"\"Generate a square mask for the sequence. The masked positions are filled with float('-inf').\n",
        "            Unmasked positions are filled with float(0.0).\n",
        "        \"\"\"\n",
        "        mask = (torch.triu(torch.ones(size, size)) == 1).transpose(0, 1)\n",
        "        mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0)).to(device)\n",
        "        return\n",
        "        \n",
        "  def generate_complete_mask(self, size):\n",
        "        r\"\"\"Generate a square mask for the sequence. The masked positions are filled with float('-inf').\n",
        "            Unmasked positions are filled with float(0.0).\n",
        "        \"\"\"\n",
        "        mask = torch.empty(size, size).to(device)\n",
        "        mask.fill_(float('-inf'))\n",
        "        return mask\n",
        "\n",
        "  def generate_sequence(self, src):\n",
        "    #src = [sent_len]\n",
        "    src = src.unsqueeze(1)\n",
        "    #src = [sent_len, 1]\n",
        "    generate_step = 0\n",
        "    while generate_step < 120:\n",
        "      out = self.forward(src)\n",
        "      #out = [sent_len + 1, 1, vocab_size]\n",
        "      out = torch.argmax(out[-1, :], dim=1) # [1]\n",
        "      out = out.unsqueeze(0) #[1,1]\n",
        "      src = torch.cat((src, out), dim=0)\n",
        "      generate_step += 1\n",
        "    src = src.squeeze(1)\n",
        "    return src\n",
        "  \n",
        "  def position_encoding_init(self, n_position, d_pos_vec):\n",
        "    ''' Init the sinusoid position encoding table '''\n",
        "\n",
        "    # keep dim 0 for padding token position encoding zero vector\n",
        "    position_enc = np.array([\n",
        "        [pos / np.power(10000, 2*i/d_pos_vec) for i in range(d_pos_vec)]\n",
        "        if pos != 0 else np.zeros(d_pos_vec) for pos in range(n_position)])\n",
        "\n",
        "    position_enc[1:, 0::2] = np.sin(position_enc[1:, 0::2]) # dim 2i\n",
        "    position_enc[1:, 1::2] = np.cos(position_enc[1:, 1::2]) # dim 2i+1\n",
        "    temp = torch.from_numpy(position_enc).type(torch.FloatTensor)\n",
        "    temp = temp.to(self.device)\n",
        "    return temp"
      ],
      "execution_count": 477,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "27AlSYY3hptC"
      },
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
      ],
      "execution_count": 297,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z1SpvL3Kkize"
      },
      "source": [
        "file = \"dataset.csv\"\n",
        "\n",
        "data, vocab, max_seq = get_data(file)\n",
        "seq, token_to_id, id_to_token = process_data(data, vocab, max_seq)"
      ],
      "execution_count": 511,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A4eX1Mqc-RDF",
        "outputId": "17630692-7818-4269-d8a2-b20e4518ebfc"
      },
      "source": [
        "vocab_size = len(vocab)\n",
        "hid_size = 32\n",
        "pf_size = 16\n",
        "max_len = 120\n",
        "n_head = 4\n",
        "n_layer= 8\n",
        "model = ProGen(hid_size, vocab_size, n_head, n_layer, pf_size, max_len, device).to(device)\n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')"
      ],
      "execution_count": 512,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The model has 161,122 trainable parameters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sbGladr3YVjI"
      },
      "source": [
        "bptt = 35\n",
        "def get_batch(source, i):\n",
        "    seq_len = min(bptt, len(source) - 1 - i)\n",
        "    data = source[i:i+seq_len]\n",
        "    target = source[i+1:i+1+seq_len].reshape(-1)\n",
        "    return data, target"
      ],
      "execution_count": 513,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bfqTIEKvYX-I"
      },
      "source": [
        "seq=torch.from_numpy(seq)"
      ],
      "execution_count": 514,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JIKbWpBHlTju",
        "outputId": "415c4c62-daaa-420d-dd2a-b094a2e01f4d"
      },
      "source": [
        "stats = { 'epoch':[], 'train_loss': [], 'train_perplexity': [], 'test_loss': [], 'test_perplexity': [] }\n",
        "batch_size, epochs, clip = 16, 200, 500\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, betas=(0.9, 0.98), eps=1e-9)\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "for i in range(epochs):\n",
        "  data, targets = get_batch(seq, i)\n",
        "  optimizer.zero_grad()\n",
        "  output = model(data)\n",
        "  loss = criterion(output.view(-1, len(vocab)), targets)\n",
        "  loss.backward()\n",
        "  torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5)\n",
        "  optimizer.step()\n",
        "  total_loss += loss.item()\n",
        "  stats['epoch'].append(i)\n",
        "  stats['train_loss'].append(loss.item())\n",
        "  print(i,loss.item())"
      ],
      "execution_count": 515,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 6.92336368560791\n",
            "1 6.520681381225586\n",
            "2 6.175286293029785\n",
            "3 5.58915376663208\n",
            "4 5.158373832702637\n",
            "5 4.71899938583374\n",
            "6 4.32014274597168\n",
            "7 3.9640698432922363\n",
            "8 3.6690785884857178\n",
            "9 3.4386723041534424\n",
            "10 3.274474859237671\n",
            "11 3.1297178268432617\n",
            "12 3.0211434364318848\n",
            "13 2.9239602088928223\n",
            "14 2.8185536861419678\n",
            "15 2.771613359451294\n",
            "16 2.645995855331421\n",
            "17 2.5627923011779785\n",
            "18 2.4827709197998047\n",
            "19 2.4133098125457764\n",
            "20 2.3507657051086426\n",
            "21 2.297030448913574\n",
            "22 2.241499662399292\n",
            "23 2.2194409370422363\n",
            "24 2.181461811065674\n",
            "25 2.1490275859832764\n",
            "26 2.1196694374084473\n",
            "27 2.6490957736968994\n",
            "28 2.134941339492798\n",
            "29 2.0950958728790283\n",
            "30 2.0725433826446533\n",
            "31 1.9920423030853271\n",
            "32 2.0792548656463623\n",
            "33 2.231052875518799\n",
            "34 2.00692081451416\n",
            "35 2.144277572631836\n",
            "36 2.1300559043884277\n",
            "37 2.0969722270965576\n",
            "38 2.0286571979522705\n",
            "39 1.952775478363037\n",
            "40 1.9602395296096802\n",
            "41 1.9524412155151367\n",
            "42 2.0717320442199707\n",
            "43 2.0689001083374023\n",
            "44 2.069622278213501\n",
            "45 2.11448073387146\n",
            "46 2.004620313644409\n",
            "47 2.0753719806671143\n",
            "48 1.9663002490997314\n",
            "49 1.9666070938110352\n",
            "50 1.9489233493804932\n",
            "51 1.936388373374939\n",
            "52 1.9640079736709595\n",
            "53 1.9561303853988647\n",
            "54 1.9370023012161255\n",
            "55 1.9166531562805176\n",
            "56 1.914580225944519\n",
            "57 1.9047454595565796\n",
            "58 1.9007608890533447\n",
            "59 1.9517592191696167\n",
            "60 1.9003994464874268\n",
            "61 1.8946349620819092\n",
            "62 1.9344216585159302\n",
            "63 1.8795835971832275\n",
            "64 1.8907544612884521\n",
            "65 1.8761862516403198\n",
            "66 1.9103617668151855\n",
            "67 1.8401859998703003\n",
            "68 1.901486873626709\n",
            "69 1.87278151512146\n",
            "70 1.8667610883712769\n",
            "71 1.8864316940307617\n",
            "72 1.8270548582077026\n",
            "73 1.8399263620376587\n",
            "74 1.8258984088897705\n",
            "75 1.8132253885269165\n",
            "76 1.8318989276885986\n",
            "77 1.7980926036834717\n",
            "78 1.8134443759918213\n",
            "79 1.7800242900848389\n",
            "80 1.7745075225830078\n",
            "81 1.776853322982788\n",
            "82 1.7581098079681396\n",
            "83 1.7614359855651855\n",
            "84 1.7322965860366821\n",
            "85 1.7362480163574219\n",
            "86 1.7292133569717407\n",
            "87 1.7038910388946533\n",
            "88 1.7281032800674438\n",
            "89 1.7142908573150635\n",
            "90 1.7180320024490356\n",
            "91 1.755585789680481\n",
            "92 1.7531945705413818\n",
            "93 1.7284501791000366\n",
            "94 1.746983528137207\n",
            "95 1.72672700881958\n",
            "96 1.735498309135437\n",
            "97 1.7792657613754272\n",
            "98 1.7410629987716675\n",
            "99 1.8234522342681885\n",
            "100 1.7988801002502441\n",
            "101 1.7199976444244385\n",
            "102 1.7794657945632935\n",
            "103 1.7483969926834106\n",
            "104 1.7370611429214478\n",
            "105 1.7119377851486206\n",
            "106 1.7211321592330933\n",
            "107 1.6981053352355957\n",
            "108 1.7685104608535767\n",
            "109 1.770188331604004\n",
            "110 1.7622612714767456\n",
            "111 1.7371329069137573\n",
            "112 1.7108410596847534\n",
            "113 1.725635290145874\n",
            "114 1.7225570678710938\n",
            "115 1.7072352170944214\n",
            "116 1.6950435638427734\n",
            "117 1.6780534982681274\n",
            "118 1.6882805824279785\n",
            "119 1.7073017358779907\n",
            "120 1.6981860399246216\n",
            "121 1.8155215978622437\n",
            "122 1.7350502014160156\n",
            "123 1.6985008716583252\n",
            "124 1.7028526067733765\n",
            "125 1.687544584274292\n",
            "126 1.6403262615203857\n",
            "127 1.6543993949890137\n",
            "128 1.6111235618591309\n",
            "129 1.60798978805542\n",
            "130 1.595981240272522\n",
            "131 1.6116150617599487\n",
            "132 1.6420804262161255\n",
            "133 1.6275032758712769\n",
            "134 1.673448920249939\n",
            "135 1.678754448890686\n",
            "136 1.6948246955871582\n",
            "137 1.6962488889694214\n",
            "138 1.6848615407943726\n",
            "139 1.7124369144439697\n",
            "140 1.7025158405303955\n",
            "141 1.7600603103637695\n",
            "142 1.7547575235366821\n",
            "143 1.7714405059814453\n",
            "144 1.7928706407546997\n",
            "145 1.7724618911743164\n",
            "146 1.7784312963485718\n",
            "147 1.8114182949066162\n",
            "148 1.8087934255599976\n",
            "149 1.8309892416000366\n",
            "150 1.8135665655136108\n",
            "151 1.8517265319824219\n",
            "152 1.8279825448989868\n",
            "153 1.8363115787506104\n",
            "154 1.7963045835494995\n",
            "155 1.8242981433868408\n",
            "156 1.8251808881759644\n",
            "157 1.8438893556594849\n",
            "158 1.8316341638565063\n",
            "159 1.8245453834533691\n",
            "160 1.818480134010315\n",
            "161 1.8553013801574707\n",
            "162 1.8469057083129883\n",
            "163 1.8501832485198975\n",
            "164 1.8444771766662598\n",
            "165 1.8499215841293335\n",
            "166 1.8403321504592896\n",
            "167 1.8387970924377441\n",
            "168 1.866471529006958\n",
            "169 1.8937623500823975\n",
            "170 1.8796402215957642\n",
            "171 1.8606432676315308\n",
            "172 1.8649874925613403\n",
            "173 1.8519915342330933\n",
            "174 1.8501673936843872\n",
            "175 1.8535521030426025\n",
            "176 1.8255747556686401\n",
            "177 1.8620469570159912\n",
            "178 1.8394683599472046\n",
            "179 1.8304922580718994\n",
            "180 1.8173853158950806\n",
            "181 1.7870303392410278\n",
            "182 1.7729313373565674\n",
            "183 1.7951267957687378\n",
            "184 1.8216434717178345\n",
            "185 1.8312197923660278\n",
            "186 1.875032901763916\n",
            "187 1.85935640335083\n",
            "188 1.9500434398651123\n",
            "189 1.9166325330734253\n",
            "190 1.897010326385498\n",
            "191 1.900518536567688\n",
            "192 1.875650405883789\n",
            "193 1.8858001232147217\n",
            "194 1.8990637063980103\n",
            "195 1.8937666416168213\n",
            "196 1.9675781726837158\n",
            "197 1.9473936557769775\n",
            "198 1.911573052406311\n",
            "199 1.8733172416687012\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "mcBrhx5dQr4b",
        "outputId": "afce1d15-a3f8-4f30-ae65-4e93374b8051"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(stats['epoch'], stats['train_loss'])\n",
        "plt.show()"
      ],
      "execution_count": 516,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P-clZE_xVnPG",
        "outputId": "444db71a-2b76-4553-dfae-95f285f564fe"
      },
      "source": [
        "test_x[1,50:]"
      ],
      "execution_count": 475,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([  2,   2,   2,   2,   2,   2,   2,   2,   2,   2, 492, 426, 426, 832,\n",
              "        607, 671, 144, 174, 933, 426, 607, 426,  84, 607, 426, 607,  45, 426,\n",
              "        607, 426,  45, 607, 164, 933, 607,  84,  40,  84, 806, 144, 144, 671,\n",
              "        144, 551, 956, 144, 164, 551,  40,  84, 144, 144, 551, 551, 607,  84,\n",
              "        671, 806, 806, 933,  84, 607, 100,  28, 806, 832, 956, 607, 832, 933,\n",
              "        100, 475, 100, 806, 164, 671, 100, 901,  84, 475, 551,  40, 426, 426,\n",
              "         84, 551, 607, 607, 572, 164, 164,  40, 956, 956, 100,  40, 475, 100,\n",
              "        901, 100, 806,  40,  40, 901, 806, 492, 174,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 475
        }
      ]
    }
  ]
}